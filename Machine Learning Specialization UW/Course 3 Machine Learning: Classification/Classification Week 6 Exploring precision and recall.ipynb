{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "products = pd.read_csv('amazon_baby.csv')\n",
    "\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform text cleaning\n",
    "\n",
    "We start by removing punctuation, so that words \"cake.\" and \"cake!\" are counted as the same word.\n",
    "\n",
    "  *  Write a function remove_punctuation that strips punctuation from a line of text\n",
    "  *  Apply this function to every element in the review column of products, and save the result to a new column review_clean.\n",
    "\n",
    "Refer to your tool's manual for string processing capabilities. Python lets us express the operation in a succinct way, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator) \n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Sentiments\n",
    "\n",
    "We will ignore all reviews with rating = 3, since they tend to have a neutral sentiment. In SFrame, for instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products[products['rating'] != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be positive reviews, while the ones with rating of 2 or lower are negative. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label. A good way is to create an anonymous function that converts a rating into a class label and then apply that function to every element in the rating column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "5  When the Binky Fairy came to our house, we did...       5   \n",
       "\n",
       "                                        review_clean  sentiment  \n",
       "1  it came early and was not disappointed i love ...          1  \n",
       "2  Very soft and comfortable and warmer than it l...          1  \n",
       "3  This is a product well worth the purchase  I h...          1  \n",
       "4  All of my kids have cried nonstop when I tried...          1  \n",
       "5  When the Binky Fairy came to our house we didn...          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test sets\n",
    "\n",
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "5  When the Binky Fairy came to our house, we did...       5   \n",
       "\n",
       "                                        review_clean  sentiment  \n",
       "1  it came early and was not disappointed i love ...          1  \n",
       "2  Very soft and comfortable and warmer than it l...          1  \n",
       "3  This is a product well worth the purchase  I h...          1  \n",
       "4  All of my kids have cried nonstop when I tried...          1  \n",
       "5  When the Binky Fairy came to our house we didn...          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "train_idx = json.loads(open('module-9-assignment-train-idx.json').read())\n",
    "test_idx = json.loads(open('module-9-assignment-test-idx.json').read())\n",
    "\n",
    "train_data = products.iloc[train_idx]\n",
    "test_data = products.iloc[test_idx]\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the word count vector for each review\n",
    "\n",
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as bag-of-word features. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n",
    "\n",
    "  *  Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "  *  Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "  *  Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix.\n",
    "  *  Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix.\n",
    "\n",
    "The following cell uses CountVectorizer in scikit-learn. Notice the token_pattern argument in the constructor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "     # Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a sentiment classifier with logistic regression\n",
    "\n",
    "Learn a logistic regression classifier using the training data. If you are using scikit-learn, you should create an instance of the LogisticRegression class and then call the method fit() to train the classifier. This model should use the sparse word count matrix (train_matrix) as features and the column sentiment of train_data as the target. Use the default values for other parameters. Call this model model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression().fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "We will explore the advanced model evaluation concepts that were discussed in the lectures.\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "One performance metric we will use for our more advanced exploration is accuracy, which we have seen many times in past assignments. Recall that the accuracy is given by\n",
    "\n",
    "accuracy=# correctly classified data points / # total data points\n",
    "\n",
    "Compute the accuracy on the test set using your tool of choice. If you are using scikit-learn, you can use the pre-defined method accuracy_score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.932295416367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true=test_data['sentiment'], y_pred=model.predict(test_matrix))\n",
    "print(\"Test Accuracy: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline: Majority class prediction\n",
    "\n",
    "Recall from an earlier assignment that we used the majority class classifier as a baseline (i.e reference) model for a point of comparison with a more sophisticated classifier. The majority classifier model predicts the majority class for all data points.\n",
    "\n",
    "Typically, a good model should beat the majority class classifier. Since the majority class in this dataset is the positive class (i.e., there are more positive than negative reviews), the accuracy of the majority class classifier is simply the fraction of positive reviews in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (majority class classifier): 0.8427825773938085\n"
     ]
    }
   ],
   "source": [
    "baseline = len(test_data[test_data['sentiment'] == 1])/len(test_data)\n",
    "print(\"Baseline accuracy (majority class classifier): %s\" % baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Using accuracy as the evaluation metric, was our logistic regression model better than the majority class classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "The accuracy, while convenient, does not tell the whole story. For a fuller picture, we turn to the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " target_label | predicted_label | count \n",
      "--------------+-----------------+-------\n",
      "     -1       |       -1        |  3788\n",
      "     -1       |        1        |  1453\n",
      "      1       |       -1        |   804\n",
      "      1       |        1        | 27291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmat = confusion_matrix(y_true=test_data['sentiment'],\n",
    "                        y_pred=model.predict(test_matrix),\n",
    "                        labels=model.classes_)    # use the same order of class as the LR model.\n",
    "print(' target_label | predicted_label | count ')\n",
    "print('--------------+-----------------+-------')\n",
    "# Print out the confusion matrix.\n",
    "# NOTE: Your tool may arrange entries in a different order. Consult appropriate manuals.\n",
    "for i, target_label in enumerate(model.classes_):\n",
    "    for j, predicted_label in enumerate(model.classes_):\n",
    "        print('{0:^13} | {1:^15} | {2:5d}'.format(target_label, predicted_label, cmat[i,j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Question 2\n",
    "How many predicted values in the test set are false positives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1453"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the cost of mistakes\n",
    "\n",
    "Put yourself in the shoes of a manufacturer that sells a baby product on Amazon.com and you want to monitor your product's reviews in order to respond to complaints. Even a few negative reviews may generate a lot of bad publicity about the product. So you don't want to miss any reviews with negative sentiments --- you'd rather put up with false alarms about potentially negative reviews instead of missing negative reviews entirely. In other words, false positives cost more than false negatives. (It may be the other way around for other scenarios, but let's stick with the manufacturer's scenario for now.)\n",
    "\n",
    "Suppose you know the costs involved in each kind of mistake:\n",
    "\n",
    " *   \\$100 for each false positive.\n",
    " *   \\$1 for each false negative.\n",
    " *   Correctly classified reviews incur no cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_model = 1453 * 100 +804 * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Consider the scenario where each false positive costs \\$100 and each false negative \\$1.\n",
    "\n",
    "Given the stipulation, what is the cost associated with the logistic regression classifier's performance on the test set?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146104"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall\n",
    "\n",
    "You may not have exact dollar amounts for each kind of mistake. Instead, you may simply prefer to reduce the percentage of false positives to be less than, say, 3.5% of all positive predictions. This is where precision comes in:\n",
    "\n",
    "[precision]=[# positive data points with positive predictions]/[# all data points with positive predictions]=[# true positives]/([# true positives]+[# false positives])\n",
    "\n",
    "So to keep the percentage of false positives below 3.5% of positive predictions, we must raise the precision to 96.5% or higher.\n",
    "\n",
    "First, let us compute the precision of the logistic regression classifier on the test_data. Scikit-learn provides a predefined method for computing precision. (Consult appropriate manuals if you are using other tools.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on test data: 0.949450320067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_true=test_data['sentiment'], \n",
    "                            y_pred=model.predict(test_matrix))\n",
    "print(\"Precision on test data: %s\" % precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Out of all reviews in the test set that are predicted to be positive, what fraction of them are false positives? (Round to the second decimal place e.g. 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043586513078953684"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmat[0,1] / float(cmat.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "Based on what we learned in lecture, if we wanted to reduce this fraction of false positives to be below 3.5%, we would:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increase threshold for predicting the positive class (y^=+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complementary metric is recall, which measures the ratio between the number of true positives and that of (ground-truth) positive reviews:\n",
    "\n",
    "[recall]=[# positive data points with positive predicitions]/[# all positive data points]=[# true positives]/([# true positives]+[# false negatives])\n",
    "\n",
    "Let us compute the recall on the test_data. Scikit-learn provides a predefined method for computing recall as well. (Consult appropriate manuals if you are using other tools.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on test data: 0.971382808329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_true=test_data['sentiment'],\n",
    "                      y_pred=model.predict(test_matrix))\n",
    "print(\"Recall on test data: %s\" % recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    " What fraction of the positive reviews in the test_set were correctly predicted as positive by the classifier? Round your answer to 2 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "What is the recall value for a classifier that predicts +1 for all data points in the test_data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1\n",
    "\n",
    "recall = [# true positives]/([# true positives]+[# false negatives]), since the classifier predicts +1 for all data points in the test_data, so there is no false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall tradeoff\n",
    "\n",
    "In this part, we will explore the trade-off between precision and recall discussed in the lecture. We first examine what happens when we use a different threshold value for making class predictions. We then explore a range of threshold values and plot the associated precision-recall curve.\n",
    "Varying the threshold\n",
    "\n",
    "False positives are costly in our example, so we may want to be more conservative about making positive predictions. To achieve this, instead of thresholding class probabilities at 0.5, we can choose a higher threshold.\n",
    "\n",
    "Write a function called apply_threshold that accepts two things\n",
    "\n",
    "  *  probabilities: an Array of probability values\n",
    "  *  threshold: a float between 0 and 1\n",
    "\n",
    "The function should return an array, where each element is set to +1 or -1 depending whether the corresponding probability exceeds threshold.\n",
    "\n",
    "Using the model you trained, compute the class probability values P(y=+1|x,w) for the data points in the test_data. Then use thresholds set at 0.5 (default) and 0.9 to make predictions from these probability values.\n",
    "\n",
    "Note. If you are using scikit-learn, make sure to use predict_proba() function, not decision_function(). Also, note that the predict_proba() function returns the probability values for both classes +1 and -1. So make sure to extract the second column, which correspond to the class +1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities = model.predict_proba(test_matrix)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "What happens to the number of positive predicted reviews as the threshold increased from 0.5 to 0.9? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fewer reviews are predicted to be positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the associated precision and recall as the threshold varies\n",
    "\n",
    "By changing the probability threshold, it is possible to influence precision and recall. Compute precision and recall for threshold values 0.5 and 0.9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_threshold(probabilities, threshold):\n",
    "    # +1 if >= threshold and -1 otherwise.\n",
    "    ans = np.array([+1 if x >= threshold else -1 for x in probabilities])\n",
    "    return ans\n",
    "\n",
    "predict_05 = apply_threshold(probabilities, 0.5)\n",
    "predict_09 = apply_threshold(probabilities, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on test data (threshold 0.5): 0.949450320067\n",
      "Recall on test data (threshold 0.5)   : 0.971382808329\n"
     ]
    }
   ],
   "source": [
    "precision_05 = precision_score(y_true=test_data['sentiment'], \n",
    "                            y_pred=predict_05)\n",
    "\n",
    "recall_05 = recall_score(y_true=test_data['sentiment'],\n",
    "                      y_pred=predict_05)\n",
    "\n",
    "print(\"Precision on test data (threshold 0.5): %s\" % precision_05)\n",
    "print(\"Recall on test data (threshold 0.5)   : %s\" % recall_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on test data (threshold 0.9): 0.981491084606\n",
      "Recall on test data (threshold 0.9)   : 0.875778608293\n"
     ]
    }
   ],
   "source": [
    "precision_09 = precision_score(y_true=test_data['sentiment'], \n",
    "                            y_pred=predict_09)\n",
    "\n",
    "recall_09 = recall_score(y_true=test_data['sentiment'],\n",
    "                      y_pred=predict_09)\n",
    "\n",
    "print(\"Precision on test data (threshold 0.9): %s\" % precision_09)\n",
    "print(\"Recall on test data (threshold 0.9)   : %s\" % recall_09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "What happens to the number of positive predicted reviews as the threshold increased from 0.5 to 0.9? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fewer reviews are predicted to be positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "Consider the metrics obtained from setting the threshold to 0.5 and to 0.9.\n",
    "\n",
    "Does the precision increase with a higher threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall curve\n",
    "\n",
    "Now, we will explore various different values of tresholds, compute the precision and recall scores, and then plot the precision-recall curve. Use 100 equally spaced values between 0.5 and 1. In Python, we run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5         0.50505051  0.51010101  0.51515152  0.52020202  0.52525253\n",
      "  0.53030303  0.53535354  0.54040404  0.54545455  0.55050505  0.55555556\n",
      "  0.56060606  0.56565657  0.57070707  0.57575758  0.58080808  0.58585859\n",
      "  0.59090909  0.5959596   0.6010101   0.60606061  0.61111111  0.61616162\n",
      "  0.62121212  0.62626263  0.63131313  0.63636364  0.64141414  0.64646465\n",
      "  0.65151515  0.65656566  0.66161616  0.66666667  0.67171717  0.67676768\n",
      "  0.68181818  0.68686869  0.69191919  0.6969697   0.7020202   0.70707071\n",
      "  0.71212121  0.71717172  0.72222222  0.72727273  0.73232323  0.73737374\n",
      "  0.74242424  0.74747475  0.75252525  0.75757576  0.76262626  0.76767677\n",
      "  0.77272727  0.77777778  0.78282828  0.78787879  0.79292929  0.7979798\n",
      "  0.8030303   0.80808081  0.81313131  0.81818182  0.82323232  0.82828283\n",
      "  0.83333333  0.83838384  0.84343434  0.84848485  0.85353535  0.85858586\n",
      "  0.86363636  0.86868687  0.87373737  0.87878788  0.88383838  0.88888889\n",
      "  0.89393939  0.8989899   0.9040404   0.90909091  0.91414141  0.91919192\n",
      "  0.92424242  0.92929293  0.93434343  0.93939394  0.94444444  0.94949495\n",
      "  0.95454545  0.95959596  0.96464646  0.96969697  0.97474747  0.97979798\n",
      "  0.98484848  0.98989899  0.99494949  1.        ]\n"
     ]
    }
   ],
   "source": [
    "threshold_values = np.linspace(0.5, 1, num=100)\n",
    "print(threshold_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the values of threshold, we first obtain class predictions using that threshold and then compute the precision and recall scores. Save the precision scores and recall scores to lists precision_all and recall_all, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_all = []\n",
    "recall_all = []\n",
    "for threshold in threshold_values:\n",
    "    predict_val = apply_threshold(probabilities, threshold)\n",
    "    precision_val = precision_score(y_true=test_data['sentiment'], \n",
    "                            y_pred=predict_val)\n",
    "    recall_val = recall_score(y_true=test_data['sentiment'],\n",
    "                      y_pred=predict_val)\n",
    "    precision_all.append(precision_val)\n",
    "    recall_all.append(recall_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the precision-recall curve to visualize the precision-recall tradeoff as we vary the threshold. Implement the function plot_pr_curve that generates a connected scatter plot from the lists of precision and recall scores. The function would be implemented in matplotlib as follows; for other tools, consult appropriate manuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_pr_curve(precision, recall, title):\n",
    "    plt.rcParams['figure.figsize'] = 7, 5\n",
    "    plt.locator_params(axis = 'x', nbins = 5)\n",
    "    plt.plot(precision, recall, 'b-', linewidth=4.0, color = '#B0017F')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the function plot_pr_curve is complete, plot the precision-recall curve for the test set by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFNCAYAAACUvLFdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7124a2c1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pr_curve(precision_all, recall_all, 'Precision recall curve (all)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10\n",
    "Among all the threshold values tried, what is the smallest threshold value that achieves a precision of 96.5% or better? Round your answer to 3 decimal places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70707070707070707"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_idx = next(x[0] for x in enumerate(precision_all) if x[1] > 0.965)\n",
    "\n",
    "threshold_values[precision_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70707070707070707"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_values[np.array(precision_all) >= 0.965].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 11\n",
    "Using threshold = 0.98, how many false negatives do we get on the test_data? \n",
    "\n",
    "Compute confusion matrix to evaluate the accuracy of a classification\n",
    "\n",
    "By definition a confusion matrix C is such that C_{i, j} is equal to the number of observations known to be in group i but predicted to be in group j.\n",
    "\n",
    "Thus in binary classification, the count of true negatives is C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5047,   194],\n",
       "       [ 8209, 19886]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_098 = apply_threshold(probabilities, 0.98)\n",
    "cmat_098 = confusion_matrix(y_true=test_data['sentiment'],\n",
    "                        y_pred=predict_098,\n",
    "                        labels=model.classes_)\n",
    "cmat_098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8209"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmat_098[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating specific search terms\n",
    "\n",
    "So far, we looked at the number of false positives for the entire test set. In this section, let's select reviews using a specific search term and optimize the precision on these reviews only. After all, a manufacturer would be interested in tuning the false positive rate just for their products (the reviews they want to read) rather than that of the entire set of products on Amazon.\n",
    "\n",
    "#### Precision-Recall on all baby related items\n",
    "\n",
    "From the test set, select all the reviews for all products with the word 'baby' in them. If you are using SFrame, generate a binary mask with apply() and index test_data with the mask. Save the selection to a new data frame named baby_reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>4</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>4</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Baby's First Year Undated Wall Calendar with S...</td>\n",
       "      <td>I searched high and low for a first year calen...</td>\n",
       "      <td>5</td>\n",
       "      <td>I searched high and low for a first year calen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Newborn Baby Tracker&amp;reg; - Round the Clock Ch...</td>\n",
       "      <td>This is the best way to keep track of when you...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is the best way to keep track of when you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  \\\n",
       "9    Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "10   Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "56   Baby's First Year Undated Wall Calendar with S...   \n",
       "59                           Our Baby Girl Memory Book   \n",
       "112  Newborn Baby Tracker&reg; - Round the Clock Ch...   \n",
       "\n",
       "                                                review  rating  \\\n",
       "9    This has been an easy way for my nanny to reco...       4   \n",
       "10   I love this journal and our nanny uses it ever...       4   \n",
       "56   I searched high and low for a first year calen...       5   \n",
       "59   Absolutely love it and all of the Scripture in...       5   \n",
       "112  This is the best way to keep track of when you...       5   \n",
       "\n",
       "                                          review_clean  sentiment  \n",
       "9    This has been an easy way for my nanny to reco...          1  \n",
       "10   I love this journal and our nanny uses it ever...          1  \n",
       "56   I searched high and low for a first year calen...          1  \n",
       "59   Absolutely love it and all of the Scripture in...          1  \n",
       "112  This is the best way to keep track of when you...          1  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baby_in_name(name):\n",
    "    if type(name) is str:\n",
    "        if \"baby\" in name.lower():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "baby_reviews = test_data[test_data['name'].apply(baby_in_name)]\n",
    "baby_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's predict the probability of classifying these reviews as positive. Make sure to convert the column review_clean of baby_reviews into a 2D array before computing class probability values. In scikit-learn, this task would be implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baby_matrix = vectorizer.transform(baby_reviews['review_clean'])\n",
    "probabilities = model.predict_proba(baby_matrix)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the precision-recall curve for the baby_reviews dataset. We again use 100 equally spaced values between 0.5 and 1 for the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold_values = np.linspace(0.5, 1, num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the values of threshold, we first obtain class predictions for baby_reviews using that threshold. Then we compute the precision and recall scores for baby_reviews. Save the precision scores and recall scores to lists precision_all and recall_all, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_all = []\n",
    "recall_all = []\n",
    "for threshold in threshold_values:\n",
    "    predict_val = apply_threshold(probabilities, threshold)\n",
    "    precision_val = precision_score(y_true=baby_reviews['sentiment'], \n",
    "                            y_pred=predict_val)\n",
    "    recall_val = recall_score(y_true=baby_reviews['sentiment'],\n",
    "                      y_pred=predict_val)\n",
    "    precision_all.append(precision_val)\n",
    "    recall_all.append(recall_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the precision-recall curve for baby_reviews only by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFcCAYAAABFvY7FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f711ead4240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pr_curve(precision_all, recall_all, \"Precision-Recall (Baby)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 12\n",
    "Questions 12 and 13 are concerned with the reviews that contain the word baby.\n",
    "\n",
    "Among all the threshold values tried, what is the smallest threshold value that achieves a precision of 96.5% or better for the reviews of data in baby_reviews? Round your answer to 3 decimal places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73232323232323238"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_idx = next(x[0] for x in enumerate(precision_all) if x[1] > 0.965)\n",
    "\n",
    "threshold_values[precision_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73232323232323238"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_values[np.array(precision_all) >= 0.965].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 13\n",
    "Questions 12 and 13 are concerned with the reviews that contain the word baby.\n",
    "\n",
    "Is this threshold value smaller or larger than the threshold used for the entire dataset to achieve the same specified precision of 96.5%? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Larger"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
