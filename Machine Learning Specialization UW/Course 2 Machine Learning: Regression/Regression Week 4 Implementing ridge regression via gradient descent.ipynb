{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>7639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>8062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>7503.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0       3.0       1.00       1180.0   \n",
       "1  6414100192  20141209T000000  538000.0       3.0       2.25       2570.0   \n",
       "2  5631500400  20150225T000000  180000.0       2.0       1.00        770.0   \n",
       "3  2487200875  20141209T000000  604000.0       4.0       3.00       1960.0   \n",
       "4  1954400510  20150218T000000  510000.0       3.0       2.00       1680.0   \n",
       "\n",
       "   sqft_lot floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650      1           0     0     ...          7        1180   \n",
       "1      7242      2           0     0     ...          7        2170   \n",
       "2     10000      1           0     0     ...          6         770   \n",
       "3      5000      1           0     0     ...          7        1050   \n",
       "4      8080      1           0     0     ...          8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0         1340.0      5650.0  \n",
       "1         1690.0      7639.0  \n",
       "2         2720.0      8062.0  \n",
       "3         1360.0      5000.0  \n",
       "4         1800.0      7503.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':str, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "house = pd.read_csv('kc_house_data.csv', dtype = dtype_dict)\n",
    "house_train = pd.read_csv('kc_house_train_data.csv', dtype = dtype_dict)\n",
    "house_test = pd.read_csv('kc_house_test_data.csv', dtype = dtype_dict)\n",
    "\n",
    "house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>7639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>8062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>7503.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0       3.0       1.00       1180.0   \n",
       "1  6414100192  20141209T000000  538000.0       3.0       2.25       2570.0   \n",
       "2  5631500400  20150225T000000  180000.0       2.0       1.00        770.0   \n",
       "3  2487200875  20141209T000000  604000.0       4.0       3.00       1960.0   \n",
       "4  1954400510  20150218T000000  510000.0       3.0       2.00       1680.0   \n",
       "\n",
       "   sqft_lot floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650      1           0     0     ...          7        1180   \n",
       "1      7242      2           0     0     ...          7        2170   \n",
       "2     10000      1           0     0     ...          6         770   \n",
       "3      5000      1           0     0     ...          7        1050   \n",
       "4      8080      1           0     0     ...          8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0         1340.0      5650.0  \n",
       "1         1690.0      7639.0  \n",
       "2         2720.0      8062.0  \n",
       "3         1360.0      5000.0  \n",
       "4         1800.0      7503.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0114101516</td>\n",
       "      <td>20140528T000000</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>19901</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1430</td>\n",
       "      <td>0</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7558</td>\n",
       "      <td>-122.229</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>12697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9297300055</td>\n",
       "      <td>20150124T000000</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1980</td>\n",
       "      <td>970</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>98126</td>\n",
       "      <td>47.5714</td>\n",
       "      <td>-122.375</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1202000200</td>\n",
       "      <td>20141103T000000</td>\n",
       "      <td>233000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>4697</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>1941</td>\n",
       "      <td>0</td>\n",
       "      <td>98002</td>\n",
       "      <td>47.3048</td>\n",
       "      <td>-122.218</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>4705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8562750320</td>\n",
       "      <td>20141110T000000</td>\n",
       "      <td>580500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>3980</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2320</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5391</td>\n",
       "      <td>-122.070</td>\n",
       "      <td>2580.0</td>\n",
       "      <td>3980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7589200193</td>\n",
       "      <td>20141110T000000</td>\n",
       "      <td>535000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1090</td>\n",
       "      <td>0</td>\n",
       "      <td>1929</td>\n",
       "      <td>0</td>\n",
       "      <td>98117</td>\n",
       "      <td>47.6889</td>\n",
       "      <td>-122.375</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>5080.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  0114101516  20140528T000000  310000.0       3.0        1.0       1430.0   \n",
       "1  9297300055  20150124T000000  650000.0       4.0        3.0       2950.0   \n",
       "2  1202000200  20141103T000000  233000.0       3.0        2.0       1710.0   \n",
       "3  8562750320  20141110T000000  580500.0       3.0        2.5       2320.0   \n",
       "4  7589200193  20141110T000000  535000.0       3.0        1.0       1090.0   \n",
       "\n",
       "   sqft_lot floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0     19901    1.5           0     0     ...          7        1430   \n",
       "1      5000      2           0     3     ...          9        1980   \n",
       "2      4697    1.5           0     0     ...          6        1710   \n",
       "3      3980      2           0     0     ...          8        2320   \n",
       "4      3000    1.5           0     0     ...          8        1090   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1927             0    98028  47.7558 -122.229   \n",
       "1            970      1979             0    98126  47.5714 -122.375   \n",
       "2              0      1941             0    98002  47.3048 -122.218   \n",
       "3              0      2003             0    98027  47.5391 -122.070   \n",
       "4              0      1929             0    98117  47.6889 -122.375   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0         1780.0     12697.0  \n",
       "1         2140.0      4000.0  \n",
       "2         1030.0      4705.0  \n",
       "3         2580.0      3980.0  \n",
       "4         1570.0      5080.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, from Module 2, copy and paste the â€˜get_numpy_dataâ€™ function (or equivalent) that takes a dataframe, a list of features (e.g. [â€˜sqft_livingâ€™, â€˜bedroomsâ€™]), to be used as inputs, and a name of the output (e.g. â€˜priceâ€™). This function returns a â€˜feature_matrixâ€™ (2D array) consisting of first a column of ones followed by columns containing the values of the input features in the data set in the same order as the input list. It alsos return an â€˜output_arrayâ€™ which is an array of the values of the output in the data set (e.g. â€˜priceâ€™)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_frame, features, output):\n",
    "    data_frame['constant'] = 1 # add a constant column to an DataFrame\n",
    "    # prepend variable 'constant' to the features list\n",
    "    features = ['constant'] + features\n",
    "\n",
    "    features_dataframe = data_frame[features]\n",
    "\n",
    "    features_matrix = features_dataframe.as_matrix()\n",
    " \n",
    "    output_dataframe = data_frame[output]\n",
    "    output_array = output_dataframe.as_matrix()\n",
    "\n",
    "    return(features_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, copy and paste the â€˜predict_outputâ€™ function (or equivalent) from Module 2. This function accepts a 2D array â€˜feature_matrixâ€™ and a 1D array â€˜weightsâ€™ and return a 1D array â€˜predictionsâ€™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_outcome(feature_matrix, weights):\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to move to computing the derivative of the regression cost function. Recall that the cost function is the sum over the data points of the squared difference between an observed output and a predicted output, plus the L2 penalty term.\n",
    "\n",
    "Since the derivative of a sum is the sum of the derivatives, we can take the derivative of the first part (the RSS) as we did in the notebook for the unregularized case in Module 2 and add the derivative of the regularization part.\n",
    "\n",
    "That is, the derivative for the weight for feature i is the sum (over data points) of 2 times the product of the error and the feature itself, plus 2*l2_penalty*w[i].\n",
    "\n",
    "IMPORTANT: We will not regularize the constant. Thus, in the case of the constant, the derivative is just twice the sum of the errors (without the 2*l2_penalty*w[0] term).\n",
    "\n",
    "Recall that twice the sum of the product of two vectors is just twice the dot product of the two vectors. Therefore the derivative for the weight for feature_i is just two times the dot product between the values of feature_i and the current errors, plus 2*l2_penalty*w[i].\n",
    "\n",
    "With this in mind write the derivative function which computes the derivative of the weight given the value of the feature (over all data points) and the errors (over all data points). To decide when to we are dealing with the constant (so we don't regularize it) we added the extra parameter to the call â€˜feature_is_constantâ€™ which you should set to True when computing the derivative of the constant and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative_ridge(errors, feature, weight, l2_penalty, feature_is_constant = False):\n",
    "    if not feature_is_constant:\n",
    "        derivative = 2 * np.dot(feature, errors) + 2 * l2_penalty * weight\n",
    "    else:\n",
    "        derivative = 2 * np.dot(feature, errors)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your feature derivative function, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.6554166816e+13\n",
      "-5.6554166816e+13\n",
      "\n",
      "-22446749330.0\n",
      "-22446749330.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(house, ['sqft_living'], 'price')\n",
    "my_weights = np.array([1., 10.])\n",
    "test_predictions = predict_outcome(example_features, my_weights)\n",
    "errors = test_predictions - example_output # prediction errors\n",
    "\n",
    "# next two lines should print the same values\n",
    "print(feature_derivative_ridge(errors, example_features[:,1], my_weights[1], 1, False))\n",
    "print(np.sum(errors*example_features[:,1])*2+20.)\n",
    "print('')\n",
    "\n",
    "# next two lines should print the same values\n",
    "print(feature_derivative_ridge(errors, example_features[:,0], my_weights[0], 1, True))\n",
    "print(np.sum(errors)*2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that performs a gradient descent. The basic premise is simple. Given a starting point we update the current weights by moving in the negative gradient direction. Recall that the gradient is the direction of increase and therefore the negative gradient is the direction of decrease and we're trying to minimize a cost function.\n",
    "\n",
    "The amount by which we move in the negative gradient direction is called the â€˜step sizeâ€™. We stop when we are â€˜sufficiently closeâ€™ to the optimum. Unlike in Module 2, this time we will set a maximum number of iterations and take gradient steps until we reach this maximum number. If no maximum number is supplied, the maximum should be set 100 by default. (Use default parameter values in Python.)\n",
    "\n",
    "With this in mind, write a gradient descent function using your derivative function above. For each step in the gradient descent, we update the weight for each feature before computing our stopping criteria. The function will take the following parameters:\n",
    "\n",
    " *   2D feature matrix\n",
    " *   array of output values\n",
    " *   initial weights\n",
    " *   step size\n",
    " *   L2 penalty\n",
    " *   maximum number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression_gradient_descent(feature_matrix, output, initial_weights, step_size, l2_penalty, max_iterations=100):\n",
    "    converged = False\n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "        #while not reached maximum number of iterations:\n",
    "        \n",
    "    while max_iterations > 0:\n",
    "        # compute the predictions using your predict_output() function\n",
    "        predictions = predict_outcome(feature_matrix, weights)\n",
    "\n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        \n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            \n",
    "            # Recall that feature_matrix[:,i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i].\n",
    "            if i == 0:\n",
    "                feature_is_constant = True\n",
    "            else:\n",
    "                feature_is_constant = False\n",
    "            derivative = feature_derivative_ridge(errors, feature_matrix[:, i], weights[i], l2_penalty, feature_is_constant)\n",
    "            #(Remember: when i=0, you are computing the derivative of the constant!)\n",
    "\n",
    "            # subtract the step size times the derivative from the current weight  \n",
    "            weights[i] -= step_size * derivative\n",
    "        max_iterations -= 1\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2 penalty gets its name because it causes weights to have small L2 norms than otherwise. Let's see how large weights get penalized. Let us consider a simple model with 1 feature.\n",
    "\n",
    "  *  features: â€˜sqft_livingâ€™\n",
    "  *  output: â€˜priceâ€™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(house_train, simple_features, my_output)\n",
    "(simple_test_feature_matrix, test_output) = get_numpy_data(house_test, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, letâ€™s consider no regularization. Set the L2 penalty to 0.0 and run your ridge regression algorithm to learn the weights of the simple model (described above). Use the following parameters:\n",
    "\n",
    " *   step_size = 1e-12\n",
    " *   max_iterations = 1000\n",
    " *   initial_weights = all zeros\n",
    "\n",
    "Store the learned weights as:\n",
    "simple_weights_0_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.63113515e-01,   2.63024369e+02])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_weights_0_penalty = ridge_regression_gradient_descent(simple_feature_matrix, output, [0.0,0.0], 1e-12, 0.0, max_iterations=1000)\n",
    "simple_weights_0_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, letâ€™s consider high regularization. Set the L2 penalty to 1e11 and run your ridge regression to learn the weights of the simple model. Use the same parameters as above. Call your weights: simple_weights_high_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   9.76730382,  124.57217567])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_weights_high_penalty = ridge_regression_gradient_descent(simple_feature_matrix, output, [0.0,0.0], 1e-12, 1e11, max_iterations=1000)\n",
    "simple_weights_high_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1a1937f048>,\n",
       " <matplotlib.lines.Line2D at 0x7f1a1937f1d0>,\n",
       " <matplotlib.lines.Line2D at 0x7f1a1937f400>,\n",
       " <matplotlib.lines.Line2D at 0x7f1a1938e3c8>,\n",
       " <matplotlib.lines.Line2D at 0x7f1a1938e588>,\n",
       " <matplotlib.lines.Line2D at 0x7f1a19393438>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAD8CAYAAABO3GKQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a44dcd438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(simple_feature_matrix,output,'k.',\n",
    "        simple_feature_matrix,predict_outcome(simple_feature_matrix, simple_weights_0_penalty),'b-',\n",
    "        simple_feature_matrix,predict_outcome(simple_feature_matrix, simple_weights_high_penalty),'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "We run ridge regression to learn the weights of a simple model that has a single feature (sqft_living), once with l2_penalty=0.0 and once with l2_penalty=1e11.\n",
    "\n",
    "What is the value of the coefficient for sqft_living that you learned with no regularization, rounded to 1 decimal place? Use American-style decimals (e.g. 30.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263.02436896538489"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_weights_0_penalty[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "This question refers to the same model as the previous question.\n",
    "\n",
    "What is the value of the coefficient for sqft_living that you learned with high regularization (l2_penalty=1e11)? Use American-style decimals (e.g. 30.5) and round your answer to 1 decimal place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.57217567413909"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_weights_high_penalty[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "This question refers to the same model as the previous question.\n",
    "\n",
    "Comparing the lines you fit with the with no regularization versus high regularization (l2_penalty=1e11), which one is steeper?\n",
    "\n",
    "* Line fit with no regularization (l2_penalty=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "This question refers to the same model as the previous question.\n",
    "\n",
    "Using all zero weights, make predictions for the TEST data. In which of the following ranges does the TEST error (RSS) fall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RSS_calculation(feature_matrix, weights, output):\n",
    "    prediction = predict_outcome(feature_matrix, weights)\n",
    "    residual = output - prediction\n",
    "    RSS = (residual ** 2).sum()\n",
    "    return RSS    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS 0 weights 1.78427328614e+15\n"
     ]
    }
   ],
   "source": [
    "print(\"RSS 0 weights\", RSS_calculation(simple_test_feature_matrix, [0.0,0.0], test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS no regulation 2.75723632154e+14\n"
     ]
    }
   ],
   "source": [
    "print(\"RSS no regulation\", RSS_calculation(simple_test_feature_matrix, simple_weights_0_penalty, test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS high regulation 6.9464210149e+14\n"
     ]
    }
   ],
   "source": [
    "print(\"RSS high regulation\", RSS_calculation(simple_test_feature_matrix, simple_weights_high_penalty, test_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "We run ridge regression to learn the weights of a model that has two features (sqft_living, sqft_living15), once with l2_penalty=0.0 and once with l2_penalty=1e11.\n",
    "\n",
    "What is the value of the coefficient for sqft_living that you learned with no regularization, rounded to 1 decimal place? Use American-style decimals (e.g. 30.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2_features = ['sqft_living', 'sqft_living15']\n",
    "model_2_output = 'price'\n",
    "(model_2_feature_matrix, model_2_output) = get_numpy_data(house_train, model_2_features, model_2_output)\n",
    "\n",
    "#(model_2_test_feature_matrix, model_2_test_output) = get_numpy_data(house_test, model_2_features, model_2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243.05416982095639"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_weights_0_penalty = ridge_regression_gradient_descent(model_2_feature_matrix, model_2_output, [0.0,0.0,0.0], 1e-12, 0.0, max_iterations=1000)\n",
    "model_2_weights_0_penalty[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "This question refers to the same model as the previous question.\n",
    "\n",
    "What is the value of the coefficient for sqft_living that you learned with high regularization (l2_penalty=1e11)? Use American-style decimals (e.g. 30.5) and round your answer to 1 decimal place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.489273647123952"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_weights_high_penalty = ridge_regression_gradient_descent(model_2_feature_matrix, model_2_output, [0.0,0.0,0.0], 1e-12, 1e11, max_iterations=1000)\n",
    "model_2_weights_high_penalty[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "This question refers to the same model as the previous question.\n",
    "\n",
    "Using all zero weights, make predictions for the TEST data. In which of the following ranges does the TEST error (RSS) fall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS no regulation 2.74067615919e+14\n",
      "RSS high regulation 5.00404800501e+14\n"
     ]
    }
   ],
   "source": [
    "(test_model_2_feature_matrix, test_output) = get_numpy_data(house_test, model_2_features, my_output)\n",
    "print(\"RSS no regulation\", RSS_calculation(test_model_2_feature_matrix, model_2_weights_0_penalty, test_output))\n",
    "print(\"RSS high regulation\", RSS_calculation(test_model_2_feature_matrix, model_2_weights_high_penalty, test_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "This question refers to the same model as the previous question.\n",
    "\n",
    "Predict the price of the first house in the test set using the weights learned with no regularization. Do the same using the weights learned with high regularization. Which weights make better prediction for the first house in the test set?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the price of the first house in the test set using the weights learned with no regularization:  387465.476058\n",
      "the price of the first house in the test set using the weights learned with high regularization:  270453.530322\n"
     ]
    }
   ],
   "source": [
    "first_house = house_test[model_2_features].iloc[0].tolist()\n",
    "\n",
    "predict_price_no_reg = model_2_weights_0_penalty[0] + model_2_weights_0_penalty[1] * first_house[0] + model_2_weights_0_penalty[2] * first_house[1]\n",
    "print(\"the price of the first house in the test set using the weights learned with no regularization: \", predict_price_no_reg)\n",
    "predict_price_hi_reg = model_2_weights_high_penalty[0] + model_2_weights_high_penalty[1] * first_house[0] + model_2_weights_high_penalty[2] * first_house[1]\n",
    "print(\"the price of the first house in the test set using the weights learned with high regularization: \", predict_price_hi_reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
